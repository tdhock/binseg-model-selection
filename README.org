Experiments to support upcoming research paper about methods for model
selection with binary segmentation, to support R package
[[https://github.com/tdhock/binsegRcpp]]

** TODOs

- Compare with Julia
  https://github.com/STOR-i/Changepoints.jl/blob/master/src/BS.jl
  maybe using
  https://cran.r-project.org/web/packages/JuliaCall/readme/README.html
- MATLAB https://www.mathworks.com/help/signal/ref/findchangepts.html#mw_748d5529-e05a-4b55-a3fe-2a12a5772d22
- NAG https://www.nag.com/numeric/nl/nagdoc_latest/clhtml/g13/g13ndc.html, https://www.nag.com/content/calling-nag-fortran-routines-r, https://www.nag.com/content/nagfwrappers-r-package

** 6 Apr 2022

[[file:figure-splits-loss.R]] makes

[[file:figure-splits-loss.png]]

Figure above shows that 0/1 seq can be used for worst case of
l1,mean_norm,poisson loss, but for meanvar_norm we need 0/1/10/11
seq. Also linear data achieves best case for normal losses, and is
very close to best case for l1 and poisson. TODO figure out a simple
synthetic data sequence which achieves the best case for l1 and
poisson.

[[file:figure-timings-laplace-data.R]] makes [[file:figure-timings-meanvar_norm-data.csv]]

[[file:figure-timings-laplace.R]] reads that file and makes

[[file:figure-timings-laplace.png]]

Figure above shows that ruptures looks asymptotically slower in best
case. 
   
[[file:figure-timings-meanvar_norm-data.R]] makes [[file:figure-timings-meanvar_norm-data.csv]]

[[file:figure-timings-meanvar_norm.R]] reads that file and makes

[[file:figure-timings-meanvar_norm.png]]

Figure above shows that
- blockcpd is about the same as binsegRcpp multiset.
- for worst case changepoint is faster up to very large model sizes,
  but asymptotically slower. 

[[file:figure-timings-poisson-data.R]] makes [[file:figure-timings-poisson-data.csv]]

[[file:figure-timings-poisson.R]] reads that file and makes

[[file:figure-timings-poisson.png]]

Figure above shows that
- blockcpd about the same as binsegRcpp multiset.
- others consistent with other losses.

TODO compare both versions of blockcpd. Also compare with
max.segs=n.data since that is what blockcpd does?

** 24 Mar 2022

[[file:figure-neuroblastoma.R]] makes the figure below, which shows a real
data set for which there are differences between binsegRcpp and
ruptures/changepoint.

[[file:figure-neuroblastoma.png]]

** 23 Mar 2022

[[file:ruptures_bug.py]] and [[file:changepoint.bug.R]] used to report issues,
https://github.com/deepcharles/ruptures/issues/242 and
https://github.com/rkillick/changepoint/issues/69

** 22 Mar 2022

[[file:figure-timings-data.R]] makes [[file:figure-timings-data.csv]]

[[file:figure-timings.R]] reads that and makes

[[file:figure-timings.png]]

Figure above was created using synthetic data which achieve the
best/worst case time complexity of the binary segmentation
algorithm. For each data set of a given size N in
{2^2=4,8,16,32,...,2^20=1,048,576}, we run binary segmentation up to a
max of N/2 segments (and not going to a larger N if the algo/case
resulted in a time greater than 100 seconds). The timings suggest that
changepoint R package uses a cubic algorithm (three nested for loops)
whereas binsegRcpp uses an algorithm which is log-linear in the best
case, and quadratic in the worst case. The ruptures python module
seems to be asymptotically faster than changepoint but slower than
binsegRcpp, maybe quadratic?

[[file:figure-timings-loss.png]]

Figure above shows that loss for binsegRcpp is always less than loss
for others, suggesting that there are bugs in the other
implementations.

** 20 Jan 2022

[[file:figure-select-segments-data.R]] computes simulations using a
variety of model selection criteria, saving results to
[[file:figure-select-segments-data.csv]]

[[file:figure-select-segments.R]] reads that result CSV file and makes 

[[file:figure-select-segments.png]]
